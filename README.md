# Databricks IP Ranges Script

> **Note:** The latest updates generated by the GitHub Action can be viewed at: **[https://bhavink.github.io/databricksIPranges/](https://bhavink.github.io/databricksIPranges/)**

**Databricks** IP ranges for firewall allowlisting — **all supported clouds: AWS, Azure, and GCP** (not Azure-only).  
A Python utility that retrieves, processes, and organizes the official [Databricks IP ranges](https://www.databricks.com/networking/v1/ip-ranges.json) and produces per-cloud, PA-compatible TXT files.  
**Source (authoritative):** [Databricks IP ranges JSON](https://www.databricks.com/networking/v1/ip-ranges.json) — the docs page (`docs.databricks.com/.../ip-ranges`) is often empty or moved; the JSON is the current machine-readable source.

## Features

- Automatically fetches the latest Databricks IP ranges JSON
- Processes and organizes IP ranges by **cloud** (AWS, Azure, GCP) and **type** (inbound / outbound)
- Creates individual text files per cloud and type (e.g. `aws.txt`, `azure-outbound.txt`, `gcp.txt`)
- Format compatible with **Palo Alto Networks (PA)** devices (one CIDR per line)
- Maintains a history of JSON files
- Generates a user-friendly web interface to browse the data

## How It Works

1. Downloads the latest JSON from Databricks' official endpoint
2. Normalizes and filters by cloud, region, and type (inbound/outbound)
3. Creates separate text files per cloud/type in the `docs/output/` directory
4. Maintains a history of JSON snapshots in `docs/json-history/`
5. Generates an index page and directory listing for easy browsing and automation

## Automated Updates

The repository is updated **weekly** via [GitHub Actions](.github/workflows/update.yml) (Databricks refreshes IP ranges every two weeks). Pre-built TXT files are available in **[output/](https://bhavink.github.io/databricksIPranges/output/)** so you can download or script against them without running the extractor yourself.

## Quick Start (manual run)

Default output is **simple** (one CIDR per line). Use `--format csv` or `--format json` for other formats.

```bash
# Per cloud (AWS, Azure, or GCP) — one CIDR per line
python extract-databricks-ips.py --cloud aws
python extract-databricks-ips.py --cloud azure
python extract-databricks-ips.py --cloud gcp

# Outbound only (egress allowlisting)
python extract-databricks-ips.py --cloud aws --type outbound

# Specific regions, save to file
python extract-databricks-ips.py --cloud aws --region us-east-1,eu-west-1 --output aws-ips.txt
```

## Usage Recommendations

1. **Fork the repository** – Recommended so you control when and how you consume updates.
2. **Regular updates** – Databricks updates the JSON periodically; the weekly Action keeps the site current.
3. **Verification** – Always verify IP ranges against your requirements before implementation.
4. **Regions and clouds** – Availability may vary by cloud and region; use `--list-regions` and `--list-services` to discover options.

## Implementation Notes

The script produces output in a format compatible with Palo Alto Networks (PA) devices. Each cloud/type combination is available as a separate TXT file (e.g. `aws-outbound.txt`, `azure.txt`) for easy import into firewall rules or automation.

For full CLI options, mermaid diagrams, and automation examples, see **[RUNBOOK.md](RUNBOOK.md)** or run `python extract-databricks-ips.py --help`.

## Disclaimer

This repository and its contents are provided **"AS IS"** without warranty of any kind, either express or implied, including, but not limited to, the implied warranties of merchantability, fitness for a particular purpose, or non-infringement. The maintainers are not responsible for any damages that may occur from the use or inability to use these scripts or associated files.

## Contributions

Contributions are welcome. Feel free to:

- Open issues for discussion
- Submit pull requests
- Suggest improvements or report bugs

## License

This project is open-source and licensed under the MIT License.

## About

**Databricks** IP ranges across **AWS, Azure, and GCP** — fetched from the official Databricks JSON, organized by cloud and type (inbound/outbound), and output as TXT files compatible with Palo Alto Networks. Files are published to the [output](https://bhavink.github.io/databricksIPranges/output/) directory and updated weekly via GitHub Actions.
